{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import transformers\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: '/local2/ataylor2/llama/llama-7B-hf'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/hub.py:399\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    400\u001b[0m         path_or_repo_id,\n\u001b[1;32m    401\u001b[0m         filename,\n\u001b[1;32m    402\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    403\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    404\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    405\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    406\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    407\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    408\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    409\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    410\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    411\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    412\u001b[0m     )\n\u001b[1;32m    413\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m arg_name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrom_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_id\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     validate_repo_id(arg_value)\n\u001b[1;32m    108\u001b[0m \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:154\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m repo_id\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    155\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/local2/ataylor2/llama/llama-7B-hf'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m llama_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/local2/ataylor2/llama/llama-7B-hf\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m LlamaForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(llama_path)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[39m=\u001b[39m LlamaTokenizer\u001b[39m.\u001b[39mfrom_pretrained(llama_path)\n\u001b[1;32m      6\u001b[0m llama_pipeline \u001b[39m=\u001b[39m transformers\u001b[39m.\u001b[39mpipeline(\u001b[39m\"\u001b[39m\u001b[39mtext-generation\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39mmodel,tokenizer\u001b[39m=\u001b[39mtokenizer,torch_dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat16,device\u001b[39m=\u001b[39mdevice,)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/modeling_utils.py:3051\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m \u001b[39mif\u001b[39;00m commit_hash \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3049\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   3050\u001b[0m         \u001b[39m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m-> 3051\u001b[0m         resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m   3052\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m   3053\u001b[0m             CONFIG_NAME,\n\u001b[1;32m   3054\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   3055\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   3056\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   3057\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   3058\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   3059\u001b[0m             token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   3060\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   3061\u001b[0m             subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   3062\u001b[0m             _raise_exceptions_for_gated_repo\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   3063\u001b[0m             _raise_exceptions_for_missing_entries\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   3064\u001b[0m             _raise_exceptions_for_connection_errors\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   3065\u001b[0m         )\n\u001b[1;32m   3066\u001b[0m         commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   3067\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/hub.py:463\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThere was a specific connection error when trying to load \u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    462\u001b[0m \u001b[39mexcept\u001b[39;00m HFValidationError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    464\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncorrect path_or_model_id: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[39mreturn\u001b[39;00m resolved_file\n",
      "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: '/local2/ataylor2/llama/llama-7B-hf'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "llama_path = \"/local2/ataylor2/llama/llama-7B-hf\"\n",
    "device = \"cuda:0\"\n",
    "model = LlamaForCausalLM.from_pretrained(llama_path).to(device)\n",
    "tokenizer = LlamaTokenizer.from_pretrained(llama_path)\n",
    "\n",
    "llama_pipeline = transformers.pipeline(\"text-generation\", model=model,tokenizer=tokenizer,torch_dtype=torch.float16,device=device,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompt_dijkstra = \"find the shortest path between nodes 0 and 4 using dijkstra's algorithm on the following graph: \"\n",
    "prompt_dijkstra = prompt_dijkstra + \"(0,1),(0,2),(0,3),(0,4),(1,0),(1,2),(1,3),(1,4),(2,0),(2,1),(2,3),(2,4),(3,0),(3,1),(3,2),(3,4),(4,0),(4,1),(4,2),(4,3)\"\n",
    "algorithm_output = llama_pipeline(prompt_dijkstra, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id, max_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find the shortest path between nodes 0 and 4 using dijkstra's algorithm on the following graph: (0,1),(0,2),(0,3),(0,4),(1,0),(1,2),(1,3),(1,4),(2,0),(2,1),(2,3),(2,4),(3,0),(3,1),(3,2),(3,4),(4,0),(4,1),(4,2),(4,3)\n",
      "\n",
      "\\begin{code}\n",
      "import networkx as nx\n",
      "import numpy as np\n",
      "\n",
      "G = nx.DiGraph()\n",
      "G.add_edge(0,1)\n",
      "G.add_edge(0,2)\n",
      "G.add_edge(0,3)\n",
      "G.add_edge(0,4)\n",
      "G.add_edge(1,0)\n",
      "G.add_edge(1,2)\n",
      "G.add_edge(1,3)\n",
      "G.add_edge(1,4)\n",
      "G.add_edge(2,0)\n",
      "G.add_edge(2,1)\n",
      "G.add_edge(2,3)\n",
      "G.add_edge(2,4)\n",
      "G.add_edge(3,0)\n",
      "G.add_edge(3,1)\n",
      "G.add_edge(3,2)\n",
      "G.add_edge(3,4)\n",
      "G.add_edge(4,0)\n",
      "G.add_edge(4,1)\n",
      "G.add_edge(4,2)\n",
      "G.add_edge(4,3)\n",
      "\n",
      "def dijkstra(G, source, target):\n",
      "    dist = nx.shortest_path_length(G, source, target)\n",
      "    return dist\n",
      "\n",
      "def main():\n",
      "    print(dijkstra(G, 0, 4))\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n",
      "\\end{code}\n",
      "\n",
      "Comment: I'm not sure what you mean by \"the shortest path between nodes 0 and 4\". Do you mean the shortest path from node 0 to node 4?\n",
      "\n",
      "Comment: @JoeWiseburger yes, I mean the shortest path from node 0 to\n"
     ]
    }
   ],
   "source": [
    "print(algorithm_output[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
